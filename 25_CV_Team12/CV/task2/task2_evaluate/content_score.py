import os
import argparse
import numpy as np
from PIL import Image
from tqdm import tqdm
from skimage.metrics import structural_similarity
import csv # <--- CSV ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€

import torch
from torchvision import transforms

import ldc 

# ----------------------------------------------------
# LDC_PTH_PATH: ë³µì‚¬ëœ íŒŒì¼ ê²½ë¡œ
# ----------------------------------------------------
LDC_PTH_PATH = './ldc.pth'

# [í•µì‹¬ ìˆ˜ì •]: ëª¨ë“  ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ í†µì¼í•˜ê¸° ìœ„í•œ ì „ì—­ ë³€ìˆ˜
FIXED_H = 0
FIXED_W = 0
device = torch.device("cpu") 

# LDC ëª¨ë¸ ë¡œë“œ ë° í‰ê°€ ëª¨ë“œ ì„¤ì •
try:
    ldc_model = ldc.LDC()
    ldc_model.load_state_dict(torch.load(LDC_PTH_PATH, map_location=device))
    ldc_model.to(device).eval()
except Exception as e:
    print("\n[FATAL ERROR] LDC ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. ê²½ë¡œì™€ íŒŒì¼ ì¡´ìž¬ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    print(f"ê²½ë¡œ: {LDC_PTH_PATH}")
    print(f"ì„¸ë¶€ ì˜¤ë¥˜: {e}")
    exit()

# ----------------------------------------------------
# [ìƒˆë¡œ ì¶”ê°€ëœ í•¨ìˆ˜] CSV íŒŒì¼ ì €ìž¥ í•¨ìˆ˜
# ----------------------------------------------------
def save_scores_to_csv(results_list, final_avg, output_filename):
    """
    ê°œë³„ íŒŒì¼ì˜ ì ìˆ˜ì™€ ìµœì¢… í‰ê·  ì ìˆ˜ë¥¼ CSV íŒŒì¼ë¡œ ì €ìž¥í•©ë‹ˆë‹¤.
    """
    header = ['File_Name', 'Content_Similarity_Score']
    
    # íŒŒì¼ì„ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤. (ê¸°ì¡´ ë°ì´í„° ë®ì–´ì“°ê¸°)
    with open(output_filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(header)
        
        for fname, score in results_list:
            writer.writerow([fname, f"{score:.4f}"])
            
        # ìµœì¢… í‰ê·  ì ìˆ˜ë„ ë³„ë„ì˜ í–‰ìœ¼ë¡œ ì €ìž¥
        writer.writerow(['---', '---'])
        writer.writerow(['Average Score', f"{final_avg:.4f}"])
            
    print(f"\nâœ… Content ìœ ì‚¬ì„± ì ìˆ˜ê°€ '{output_filename}'ì— ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def calculate_ldc_edge(image_path, is_fixed_content=False):
    global FIXED_H, FIXED_W
    
    image = Image.open(image_path).convert('RGB')

    h_orig, w_orig = image.size
    
    # LDC ëª¨ë¸ ìž…ë ¥ ìš”êµ¬ ì‚¬í•­: 32ì˜ ë°°ìˆ˜ë¡œ í¬ê¸° ì¡°ì •
    h_mod32 = int(h_orig - h_orig % 32)
    w_mod32 = int(w_orig - w_orig % 32)
    
    if h_mod32 == 0 or w_mod32 == 0:
        raise ValueError(f"Image size is too small after mod-32 adjustment: {h_mod32}x{w_mod32}")

    
    # [í¬ê¸° ê³ ì • ë¡œì§]
    if is_fixed_content:
        FIXED_H = h_mod32
        FIXED_W = w_mod32
        h, w = h_mod32, w_mod32
    elif FIXED_H != 0 and FIXED_W != 0:
        h, w = FIXED_H, FIXED_W
    else:
        h, w = h_mod32, w_mod32 
        
    
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° í…ì„œ ë³€í™˜
    mean = torch.tensor([103.939, 116.779, 123.68]).to(device).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)
    
    # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ FIXED_H x FIXED_W í¬ê¸°ë¡œ ì¡°ì •í•˜ì—¬ ì „ë‹¬í•©ë‹ˆë‹¤.
    image = transforms.functional.resize(image, (h, w))
    image = transforms.functional.to_tensor(image)[None, ...].to(device) * 255

    with torch.no_grad():
        edges = ldc_model(image - mean)
    
    avg_edge = ldc.postprocess_edges(edges)
    avg_edge = torch.from_numpy(avg_edge).unsqueeze(0).unsqueeze(0) / 255

    return avg_edge


if __name__ == '__main__':
    # define cmd arguments
    parser = argparse.ArgumentParser()
    parser.add_argument('--result-folder', type=str, required=True)
    parser.add_argument('--content-folder', type=str, required=True)
    parser.add_argument('--output-csv', type=str, default='content_similarity_scores.csv', required=False) # <--- CSV ì¶œë ¥ íŒŒì¼ëª… ì¸ìž ì¶”ê°€
    
    try:
        args = parser.parse_args()
    except SystemExit:
        print("Parsing arguments failed. Please run the script in the next cell using the !python command.")
        exit()

    # check cmd arguments
    if not os.path.exists(args.result_folder):
        print('Cannot find the result folder: {0}'.format(args.result_folder))
        exit()
    if not os.path.exists(args.content_folder):
        print('Cannot find the content folder: {0}'.format(args.content_folder))
        exit()

    result_files = os.listdir(args.result_folder)
    content_files = os.listdir(args.content_folder)
    
    if not result_files or not content_files:
        print("\n[ERROR] One or both folders are EMPTY. Please check your image files.")
        exit()
        
    # [ë‹¨ì¼ ì›ë³¸ íŒŒì¼ ë¡œë“œ ë° ê³ ì • ë¡œì§]
    if len(content_files) != 1:
        print(f"\n[ERROR] Content folder must contain exactly ONE original image, found {len(content_files)}.")
        exit()
        
    single_content_fname = content_files[0]
    single_content_path = os.path.join(args.content_folder, single_content_fname)
    
    try:
        # â— ì²« ë²ˆì§¸ í˜¸ì¶œ: ê³ ì •ëœ ì›ë³¸ ì´ë¯¸ì§€ì˜ ì—ì§€ ì¶”ì¶œ ë° í¬ê¸° ê³ ì • (is_fixed_content=True)
        fixed_content_edge = calculate_ldc_edge(single_content_path, is_fixed_content=True) 
    except Exception as e:
        print(f"\n[FATAL ERROR] Failed to process the single content image: {e}")
        exit()
    # ----------------------------------------------------


    print('--------------------------------------------------------------------------------')
    print('Result Folder: {0}'.format(args.result_folder))
    print('Fixed Original Image: {0}'.format(single_content_path))
    print('Fixed Image Size (HxW): {0}x{1}'.format(FIXED_H, FIXED_W))
    print('Total Result Images to process: {0}'.format(len(result_files)))
    print('Processing Device: {0}'.format(device.type))
    print('--------------------------------------------------------------------------------')

    # calculate content ssim score
    results_list = []
    all_scores = []
    
    pbar = tqdm(result_files, total=len(result_files), unit='file')
    for idx, fname in enumerate(pbar):

        result_path = os.path.join(args.result_folder, fname)
        content_edge = fixed_content_edge # ê³ ì •ëœ ì›ë³¸ ì—ì§€ ì‚¬ìš©
        
        try:
            # â— ë‘ ë²ˆì§¸ í˜¸ì¶œ: ê²°ê³¼ ì´ë¯¸ì§€ì˜ ì—ì§€ ì¶”ì¶œ (ê³ ì •ëœ í¬ê¸° ì‚¬ìš©)
            result_edge = calculate_ldc_edge(result_path) 
        except Exception as e:
            pbar.write(f"\n[SKIP] File {fname} failed LDC processing: {e}")
            continue

        # 2. NumPy ë°°ì—´ë¡œ ë³€í™˜
        result_edge = result_edge[0].permute(1, 2, 0).cpu().numpy()
        content_edge = content_edge[0].permute(1, 2, 0).cpu().numpy()
        
        # 3. SSIM ì ìˆ˜ ê³„ì‚°
        score = structural_similarity(result_edge, content_edge, channel_axis=-1, data_range=1.0)
        
        results_list.append((fname, score)) 
        all_scores.append(score)
        pbar.set_description(f'Processing {fname} | Score: {score:.4f}') 


    # ìµœì¢… ê²°ê³¼ ì¶œë ¥ ë° CSV ì €ìž¥
    final_avg = np.mean(np.asarray(all_scores)) if all_scores else 0.0
    
    # ----------------------------------------------------
    # [ìƒˆë¡œ ì¶”ê°€ëœ ì½”ë“œ] CSV íŒŒì¼ ì €ìž¥ í˜¸ì¶œ
    # ----------------------------------------------------
    save_scores_to_csv(results_list, final_avg, args.output_csv)
    
    
    print('\n================================================================================')
    print('                ðŸŒŸ Individual Content Similiary Scores ðŸŒŸ')
    print('================================================================================')
    
    for fname, score in results_list:
        print(f"  > File: {fname:<30} | Score: {score:.4f}")

    print('--------------------------------------------------------------------------------')
    print('Final Average Content Similiary Score: {0:.4f}'.format(final_avg))
    print('================================================================================')
